{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15306948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crewai in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 2)) (0.3.27)\n",
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 3)) (0.35.3)\n",
      "Requirement already satisfied: duckduckgo-search in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 4)) (8.1.1)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 6)) (2.3.3)\n",
      "Requirement already satisfied: langchain_community in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 7)) (0.4.1)\n",
      "Requirement already satisfied: ddgs in /opt/anaconda3/envs/LLMs/lib/python3.13/site-packages (from -r ../requirements.txt (line 8)) (9.9.0)\n",
      "Collecting duckduckgo (from -r ../requirements.txt (line 9))\n",
      "  Using cached duckduckgo-0.1.tar.gz (2.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[17 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(compile('''\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m# This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<32 lines>...\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31mexec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m''' % ('/private/var/folders/zs/1pxmnc6s7b7_ft4ym5rcy30r0000gn/T/pip-install-0ke4y7nt/duckduckgo_a0e69447e11b49ad8855e03bf62c61f5/setup.py',), \"<pip-setuptools-caller>\", \"exec\"))\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<pip-setuptools-caller>\"\u001b[0m, line \u001b[35m35\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/zs/1pxmnc6s7b7_ft4ym5rcy30r0000gn/T/pip-install-0ke4y7nt/duckduckgo_a0e69447e11b49ad8855e03bf62c61f5/setup.py\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     from duckduckgo import __version__\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/zs/1pxmnc6s7b7_ft4ym5rcy30r0000gn/T/pip-install-0ke4y7nt/duckduckgo_a0e69447e11b49ad8855e03bf62c61f5/duckduckgo.py\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     import urllib2\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'urllib2'\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9562bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LLMs/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from huggingface_hub import InferenceClient\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da11f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importaci√≥n exitosa de los tres agentes.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "current = os.getcwd()\n",
    "while True:\n",
    "    possible_src = os.path.join(current, \"src\")\n",
    "    if os.path.exists(possible_src):\n",
    "        sys.path.append(possible_src)\n",
    "        break\n",
    "    parent = os.path.dirname(current)\n",
    "    if parent == current:\n",
    "        raise FileNotFoundError(\" No se encontr√≥ una carpeta llamada 'src'.\")\n",
    "    current = parent\n",
    "\n",
    "# Ahora importa tus clases\n",
    "from agents import ResearcherAgent, WriterAgent, ReviewerAgent\n",
    "print(\"Importaci√≥n exitosa de los tres agentes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847a2210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WriterAgent conectado a Zephyr 7B Beta (Hugging Face).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/LLMs/lib/python3.13/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Researcher Agent buscando informaci√≥n...\n",
      "\n",
      "üîç Ejecutando b√∫squeda para: Impact of synthetic data in healthcare site:researchgate.net OR site:medium.com OR site:arxiv.org\n",
      "B√∫squeda completada.\n",
      "\n",
      " Writer Agent generando primer borrador...\n",
      "\n",
      "Resumen generado correctamente con Zephyr.\n",
      "\n",
      " Reviewer Agent analizando el primer borrador...\n",
      "\n",
      " Reviewer revisando el texto...\n",
      " An√°lisis completado.\n",
      "\n",
      "Comentario del Reviewer:\n",
      "  Texto con posibles inconsistencias o tono negativo. (confianza: 0.63) \n",
      "\n",
      "‚úèÔ∏è Writer Agent reescribiendo el texto seg√∫n comentarios...\n",
      "\n",
      "Resumen generado correctamente con Zephyr.\n",
      "\n",
      "\n",
      " Workflow completado exitosamente. Archivos guardados en /outputs/\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Multi-Agent Research Workflow\n",
    "# ==========================================================\n",
    "from agents import ResearcherAgent, WriterAgent, ReviewerAgent\n",
    "from huggingface_hub import login\n",
    "import os, json\n",
    "\n",
    "#  Configurar token de Hugging Face\n",
    "HF_TOKEN = \"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\"\n",
    "login(HF_TOKEN)\n",
    "\n",
    "#  Crear los agentes\n",
    "researcher = ResearcherAgent()\n",
    "writer = WriterAgent(HF_TOKEN)\n",
    "reviewer = ReviewerAgent()\n",
    "\n",
    "#  Definir el tema de investigaci√≥n\n",
    "topic = \"Impact of synthetic data in healthcare\"\n",
    "\n",
    "# ==========================================================\n",
    "# Ciclo 1 ‚Äî Researcher ‚Üí Writer ‚Üí Reviewer\n",
    "# ==========================================================\n",
    "print(\" Researcher Agent buscando informaci√≥n...\\n\")\n",
    "raw_results = researcher.search(topic)\n",
    "\n",
    "print(\" Writer Agent generando primer borrador...\\n\")\n",
    "draft = writer.write_summary(topic, raw_results)\n",
    "\n",
    "print(\" Reviewer Agent analizando el primer borrador...\\n\")\n",
    "review_feedback = reviewer.review(draft)\n",
    "interpretation = reviewer.interpret_feedback(review_feedback)\n",
    "\n",
    "print(\"Comentario del Reviewer:\\n\", interpretation, \"\\n\")\n",
    "\n",
    "# ==========================================================\n",
    "#  Ciclo 2 ‚Äî Writer integra comentarios del Reviewer\n",
    "# ==========================================================\n",
    "improvement_prompt = f\"\"\"\n",
    "El siguiente texto fue revisado y recibi√≥ este comentario del revisor:\n",
    "\"{interpretation}\"\n",
    "\n",
    "Por favor, reescribe el texto mejorando su coherencia y claridad,\n",
    "manteniendo la estructura en formato Markdown (# Introduction, # Key Findings, etc.),\n",
    "sin inventar datos ni eliminar informaci√≥n esencial.\n",
    "\n",
    "Texto original:\n",
    "{draft}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Writer Agent reescribiendo el texto seg√∫n comentarios...\\n\")\n",
    "revised_text = writer.write_summary(topic, improvement_prompt)\n",
    "\n",
    "# ==========================================================\n",
    "#  Guardar resultados finales\n",
    "# ==========================================================\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Primer borrador\n",
    "with open(\"../outputs/research_summary_draft.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(draft)\n",
    "\n",
    "# Revisi√≥n final\n",
    "final_text = revised_text + \"\\n\\n---\\n\\n\" + f\"**Reviewer feedback:** {interpretation}\"\n",
    "with open(\"../outputs/research_summary_final.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_text)\n",
    "\n",
    "# Resultados del Reviewer\n",
    "review_data = {\n",
    "    \"label\": review_feedback[0][\"label\"],\n",
    "    \"score\": float(review_feedback[0][\"score\"]),\n",
    "    \"interpretation\": interpretation\n",
    "}\n",
    "with open(\"../outputs/review.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(review_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n Workflow completado exitosamente. Archivos guardados en /outputs/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
